name: PySpark compatibility tests

on:
  push:
  workflow_dispatch:

jobs:
  test:
    runs-on: "ubuntu-latest"
    strategy:
      fail-fast: false
    steps:
      - name: Checkout source
        uses: actions/checkout@v3
      - name: Setup Java
        uses: actions/setup-java@v3
        with:
          distribution: "zulu"
          java-version: "11"
      - name: Setup Conda Environment
        uses: conda-incubator/setup-miniconda@v2
        with:
          miniforge-variant: Mambaforge
          miniforge-version: latest
          use-mamba: true
          channel-priority: strict
          python-version: 3.9 
          environment-file: continuous_integration/environment-spark.yml
          activate-environment: test-environment
          auto-activate-base: false

      - name: Install
        shell: bash -l {0}
        run: python -m pip install -e .[dataframe]

      - name: Run tests
        shell: bash -l {0}
        run: pytest dask -m spark 
